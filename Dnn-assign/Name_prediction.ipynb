{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are provided with some data of Names(Male and Female). So we need to predict out model based on this data such that it should be able to predict that the given name belongs to a male or a female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and store the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_male = pd.read_table(\"./Data/male.txt\",comment='#', names=['Name'])\n",
    "data_male['M_F_P'] = \"Male\"\n",
    "data_female = pd.read_table(\"./Data/female.txt\",comment='#',names=['Name'])\n",
    "data_female['M_F_P'] = \"Female\"\n",
    "#data_pet = pd.read_csv(\"./Data/pet.txt\",sep=\"\\t+\",comment='#',names=['Name','M_F_P'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine both the dataframes into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data_male, data_female], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training function of **Keras** accepts numerical data as input so we need to convert strings( names) into some numeric form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Accept all names into lower case.\n",
    "    Find out ASCII value of each character.\n",
    "    And then normalize the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "nums = []\n",
    "for i in data.Name:\n",
    "    nums.append([((ord(c)-96)/26) for c in i.lower()])    \n",
    "    if max_len < len(i):\n",
    "        max_len = len(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty matrix to store the data of size = (maximum_length_of_any_word) * (Total_Length)\n",
    "Max. size because we need to add padding for each word to match the input nodes of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x = np.zeros((len(data.Name), max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now store names(ascii values) into empty matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(nums)):\n",
    "    for j in range(0,len(nums[i])):\n",
    "        data_x[i][j] = nums[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_y = data.M_F_P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.20, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6355"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply one hot coding out output data(training as well as testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "train_y = keras.utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "test_y = keras.utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**--Total 4 layers.**\n",
    "    1. Input layer - 15 Nodes. i.e. Max. length of any word.\n",
    "    2. 2 hidden layers - (1st with 524 nodes and second with 1024 nodes.)\n",
    "    3. output layer - 2 Nodes (Male or Female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.add(Dense(524, activation='relu', input_shape=(15,)))\n",
    "model1.add(Dense(1024, activation='relu'))\n",
    "model1.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 524)               8384      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              537600    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 548,034\n",
      "Trainable params: 548,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.compile(optimizer=RMSprop(),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5084 samples, validate on 1271 samples\n",
      "Epoch 1/50\n",
      "0s - loss: 0.6585 - acc: 0.6243 - val_loss: 0.7490 - val_acc: 0.4461\n",
      "Epoch 2/50\n",
      "0s - loss: 0.6527 - acc: 0.6375 - val_loss: 0.7312 - val_acc: 0.6129\n",
      "Epoch 3/50\n",
      "0s - loss: 0.6409 - acc: 0.6503 - val_loss: 0.7701 - val_acc: 0.4540\n",
      "Epoch 4/50\n",
      "0s - loss: 0.6359 - acc: 0.6505 - val_loss: 0.6763 - val_acc: 0.6027\n",
      "Epoch 5/50\n",
      "0s - loss: 0.6316 - acc: 0.6564 - val_loss: 0.6643 - val_acc: 0.6050\n",
      "Epoch 6/50\n",
      "0s - loss: 0.6248 - acc: 0.6644 - val_loss: 0.6659 - val_acc: 0.6231\n",
      "Epoch 7/50\n",
      "0s - loss: 0.6214 - acc: 0.6707 - val_loss: 0.6656 - val_acc: 0.6310\n",
      "Epoch 8/50\n",
      "0s - loss: 0.6124 - acc: 0.6758 - val_loss: 0.6728 - val_acc: 0.6042\n",
      "Epoch 9/50\n",
      "0s - loss: 0.6100 - acc: 0.6784 - val_loss: 0.7265 - val_acc: 0.6168\n",
      "Epoch 10/50\n",
      "0s - loss: 0.6039 - acc: 0.6847 - val_loss: 0.6710 - val_acc: 0.6263\n",
      "Epoch 11/50\n",
      "0s - loss: 0.6019 - acc: 0.6810 - val_loss: 0.6749 - val_acc: 0.6090\n",
      "Epoch 12/50\n",
      "0s - loss: 0.6002 - acc: 0.6821 - val_loss: 0.6840 - val_acc: 0.5893\n",
      "Epoch 13/50\n",
      "0s - loss: 0.6008 - acc: 0.6827 - val_loss: 0.6951 - val_acc: 0.6231\n",
      "Epoch 14/50\n",
      "0s - loss: 0.5949 - acc: 0.6867 - val_loss: 0.6507 - val_acc: 0.6279\n",
      "Epoch 15/50\n",
      "0s - loss: 0.5934 - acc: 0.6908 - val_loss: 0.6798 - val_acc: 0.6184\n",
      "Epoch 16/50\n",
      "0s - loss: 0.5897 - acc: 0.6949 - val_loss: 0.7872 - val_acc: 0.5382\n",
      "Epoch 17/50\n",
      "0s - loss: 0.5927 - acc: 0.6941 - val_loss: 0.6640 - val_acc: 0.6082\n",
      "Epoch 18/50\n",
      "0s - loss: 0.5825 - acc: 0.6985 - val_loss: 0.6831 - val_acc: 0.6184\n",
      "Epoch 19/50\n",
      "0s - loss: 0.5829 - acc: 0.6973 - val_loss: 0.6803 - val_acc: 0.5972\n",
      "Epoch 20/50\n",
      "0s - loss: 0.5784 - acc: 0.7038 - val_loss: 0.7676 - val_acc: 0.5468\n",
      "Epoch 21/50\n",
      "0s - loss: 0.5841 - acc: 0.6979 - val_loss: 0.7196 - val_acc: 0.6286\n",
      "Epoch 22/50\n",
      "0s - loss: 0.5747 - acc: 0.7093 - val_loss: 0.6891 - val_acc: 0.6294\n",
      "Epoch 23/50\n",
      "0s - loss: 0.5686 - acc: 0.7081 - val_loss: 0.6749 - val_acc: 0.6255\n",
      "Epoch 24/50\n",
      "0s - loss: 0.5691 - acc: 0.7038 - val_loss: 0.6756 - val_acc: 0.6271\n",
      "Epoch 25/50\n",
      "0s - loss: 0.5689 - acc: 0.7146 - val_loss: 0.7852 - val_acc: 0.6176\n",
      "Epoch 26/50\n",
      "0s - loss: 0.5713 - acc: 0.7018 - val_loss: 0.6539 - val_acc: 0.6404\n",
      "Epoch 27/50\n",
      "0s - loss: 0.5575 - acc: 0.7152 - val_loss: 0.6996 - val_acc: 0.6098\n",
      "Epoch 28/50\n",
      "0s - loss: 0.5621 - acc: 0.7170 - val_loss: 0.6720 - val_acc: 0.6349\n",
      "Epoch 29/50\n",
      "0s - loss: 0.5563 - acc: 0.7148 - val_loss: 0.7335 - val_acc: 0.6255\n",
      "Epoch 30/50\n",
      "0s - loss: 0.5499 - acc: 0.7172 - val_loss: 0.8329 - val_acc: 0.6223\n",
      "Epoch 31/50\n",
      "0s - loss: 0.5587 - acc: 0.7221 - val_loss: 0.6979 - val_acc: 0.6349\n",
      "Epoch 32/50\n",
      "0s - loss: 0.5498 - acc: 0.7274 - val_loss: 0.7080 - val_acc: 0.6373\n",
      "Epoch 33/50\n",
      "0s - loss: 0.5467 - acc: 0.7232 - val_loss: 0.6840 - val_acc: 0.6341\n",
      "Epoch 34/50\n",
      "0s - loss: 0.5493 - acc: 0.7179 - val_loss: 0.6539 - val_acc: 0.6577\n",
      "Epoch 35/50\n",
      "0s - loss: 0.5404 - acc: 0.7276 - val_loss: 0.6798 - val_acc: 0.6271\n",
      "Epoch 36/50\n",
      "0s - loss: 0.5366 - acc: 0.7329 - val_loss: 0.7268 - val_acc: 0.5972\n",
      "Epoch 37/50\n",
      "0s - loss: 0.5365 - acc: 0.7311 - val_loss: 0.7103 - val_acc: 0.6349\n",
      "Epoch 38/50\n",
      "0s - loss: 0.5363 - acc: 0.7290 - val_loss: 0.6752 - val_acc: 0.6428\n",
      "Epoch 39/50\n",
      "0s - loss: 0.5311 - acc: 0.7390 - val_loss: 0.6861 - val_acc: 0.6577\n",
      "Epoch 40/50\n",
      "0s - loss: 0.5239 - acc: 0.7360 - val_loss: 0.7050 - val_acc: 0.6467\n",
      "Epoch 41/50\n",
      "0s - loss: 0.5260 - acc: 0.7356 - val_loss: 0.7138 - val_acc: 0.6491\n",
      "Epoch 42/50\n",
      "0s - loss: 0.5240 - acc: 0.7398 - val_loss: 0.6747 - val_acc: 0.6357\n",
      "Epoch 43/50\n",
      "0s - loss: 0.5207 - acc: 0.7417 - val_loss: 0.7128 - val_acc: 0.6412\n",
      "Epoch 44/50\n",
      "0s - loss: 0.5139 - acc: 0.7445 - val_loss: 0.7130 - val_acc: 0.6357\n",
      "Epoch 45/50\n",
      "0s - loss: 0.5093 - acc: 0.7508 - val_loss: 0.7315 - val_acc: 0.6459\n",
      "Epoch 46/50\n",
      "0s - loss: 0.5127 - acc: 0.7453 - val_loss: 0.6769 - val_acc: 0.6483\n",
      "Epoch 47/50\n",
      "0s - loss: 0.5045 - acc: 0.7516 - val_loss: 0.6888 - val_acc: 0.6467\n",
      "Epoch 48/50\n",
      "0s - loss: 0.4994 - acc: 0.7579 - val_loss: 0.7520 - val_acc: 0.6011\n",
      "Epoch 49/50\n",
      "0s - loss: 0.5098 - acc: 0.7488 - val_loss: 0.6780 - val_acc: 0.6499\n",
      "Epoch 50/50\n",
      "0s - loss: 0.5026 - acc: 0.7545 - val_loss: 0.7112 - val_acc: 0.6546\n"
     ]
    }
   ],
   "source": [
    "model_fit1 = model1.fit(X_train, \n",
    "          train_y, \n",
    "          batch_size=254,\n",
    "          epochs=50, \n",
    "          validation_split = .2,\n",
    "         verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1589 [=====================>........] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_hat1 = model1.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(y_hat1, columns=['M_F_P'])\n",
    "df_test = pd.DataFrame(y_test, columns=['M_F_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test[df_test['M_F_P'] == 'Female'] = 0 \n",
    "df_test[df_test['M_F_P'] == 'Male'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>M_F_P</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>818</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "M_F_P    0    1\n",
       "row_0          \n",
       "0      818  351\n",
       "1      186  234"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_hat1, df_test['M_F_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wrong = [im for im in zip(X_test, y_hat1, df_test['M_F_P']) if im[1] != im[2]]\n",
    "len(test_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1_acc = model_fit1.history['acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.add(Dense(254, activation='relu', input_shape=(15,)))\n",
    "#model2.add(Dense(1024, activation='relu'))\n",
    "model2.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 254)               4064      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 510       \n",
      "=================================================================\n",
      "Total params: 4,574\n",
      "Trainable params: 4,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer=RMSprop(),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5084 samples, validate on 1271 samples\n",
      "Epoch 1/50\n",
      "0s - loss: 0.6673 - acc: 0.6094 - val_loss: 0.6677 - val_acc: 0.6090\n",
      "Epoch 2/50\n",
      "0s - loss: 0.6530 - acc: 0.6353 - val_loss: 0.6765 - val_acc: 0.6090\n",
      "Epoch 3/50\n",
      "0s - loss: 0.6498 - acc: 0.6373 - val_loss: 0.6746 - val_acc: 0.6098\n",
      "Epoch 4/50\n",
      "0s - loss: 0.6470 - acc: 0.6389 - val_loss: 0.6641 - val_acc: 0.6200\n",
      "Epoch 5/50\n",
      "0s - loss: 0.6448 - acc: 0.6454 - val_loss: 0.6644 - val_acc: 0.6153\n",
      "Epoch 6/50\n",
      "0s - loss: 0.6423 - acc: 0.6463 - val_loss: 0.6634 - val_acc: 0.6192\n",
      "Epoch 7/50\n",
      "0s - loss: 0.6408 - acc: 0.6475 - val_loss: 0.6693 - val_acc: 0.6129\n",
      "Epoch 8/50\n",
      "0s - loss: 0.6393 - acc: 0.6517 - val_loss: 0.6664 - val_acc: 0.6176\n",
      "Epoch 9/50\n",
      "0s - loss: 0.6374 - acc: 0.6493 - val_loss: 0.6732 - val_acc: 0.6129\n",
      "Epoch 10/50\n",
      "0s - loss: 0.6362 - acc: 0.6503 - val_loss: 0.6598 - val_acc: 0.6255\n",
      "Epoch 11/50\n",
      "0s - loss: 0.6350 - acc: 0.6570 - val_loss: 0.6588 - val_acc: 0.6255\n",
      "Epoch 12/50\n",
      "0s - loss: 0.6331 - acc: 0.6546 - val_loss: 0.6746 - val_acc: 0.6121\n",
      "Epoch 13/50\n",
      "0s - loss: 0.6331 - acc: 0.6550 - val_loss: 0.6593 - val_acc: 0.6192\n",
      "Epoch 14/50\n",
      "0s - loss: 0.6307 - acc: 0.6576 - val_loss: 0.6612 - val_acc: 0.6192\n",
      "Epoch 15/50\n",
      "0s - loss: 0.6306 - acc: 0.6574 - val_loss: 0.6675 - val_acc: 0.6184\n",
      "Epoch 16/50\n",
      "0s - loss: 0.6291 - acc: 0.6577 - val_loss: 0.6645 - val_acc: 0.6176\n",
      "Epoch 17/50\n",
      "0s - loss: 0.6286 - acc: 0.6601 - val_loss: 0.6566 - val_acc: 0.6263\n",
      "Epoch 18/50\n",
      "0s - loss: 0.6265 - acc: 0.6609 - val_loss: 0.6658 - val_acc: 0.6200\n",
      "Epoch 19/50\n",
      "0s - loss: 0.6260 - acc: 0.6607 - val_loss: 0.6591 - val_acc: 0.6271\n",
      "Epoch 20/50\n",
      "0s - loss: 0.6247 - acc: 0.6605 - val_loss: 0.6610 - val_acc: 0.6200\n",
      "Epoch 21/50\n",
      "0s - loss: 0.6245 - acc: 0.6640 - val_loss: 0.6645 - val_acc: 0.6302\n",
      "Epoch 22/50\n",
      "0s - loss: 0.6240 - acc: 0.6656 - val_loss: 0.6597 - val_acc: 0.6239\n",
      "Epoch 23/50\n",
      "0s - loss: 0.6237 - acc: 0.6646 - val_loss: 0.6555 - val_acc: 0.6326\n",
      "Epoch 24/50\n",
      "0s - loss: 0.6214 - acc: 0.6662 - val_loss: 0.6556 - val_acc: 0.6310\n",
      "Epoch 25/50\n",
      "0s - loss: 0.6209 - acc: 0.6660 - val_loss: 0.6603 - val_acc: 0.6176\n",
      "Epoch 26/50\n",
      "0s - loss: 0.6204 - acc: 0.6684 - val_loss: 0.6609 - val_acc: 0.6263\n",
      "Epoch 27/50\n",
      "0s - loss: 0.6186 - acc: 0.6692 - val_loss: 0.6650 - val_acc: 0.5987\n",
      "Epoch 28/50\n",
      "0s - loss: 0.6197 - acc: 0.6676 - val_loss: 0.6544 - val_acc: 0.6381\n",
      "Epoch 29/50\n",
      "0s - loss: 0.6179 - acc: 0.6723 - val_loss: 0.6531 - val_acc: 0.6349\n",
      "Epoch 30/50\n",
      "0s - loss: 0.6174 - acc: 0.6719 - val_loss: 0.6550 - val_acc: 0.6294\n",
      "Epoch 31/50\n",
      "0s - loss: 0.6161 - acc: 0.6735 - val_loss: 0.6601 - val_acc: 0.6176\n",
      "Epoch 32/50\n",
      "0s - loss: 0.6168 - acc: 0.6731 - val_loss: 0.6545 - val_acc: 0.6341\n",
      "Epoch 33/50\n",
      "0s - loss: 0.6146 - acc: 0.6709 - val_loss: 0.6535 - val_acc: 0.6357\n",
      "Epoch 34/50\n",
      "0s - loss: 0.6140 - acc: 0.6737 - val_loss: 0.6575 - val_acc: 0.6310\n",
      "Epoch 35/50\n",
      "0s - loss: 0.6131 - acc: 0.6731 - val_loss: 0.6713 - val_acc: 0.6192\n",
      "Epoch 36/50\n",
      "0s - loss: 0.6142 - acc: 0.6713 - val_loss: 0.6547 - val_acc: 0.6373\n",
      "Epoch 37/50\n",
      "0s - loss: 0.6114 - acc: 0.6782 - val_loss: 0.6601 - val_acc: 0.6247\n",
      "Epoch 38/50\n",
      "0s - loss: 0.6111 - acc: 0.6751 - val_loss: 0.6525 - val_acc: 0.6318\n",
      "Epoch 39/50\n",
      "0s - loss: 0.6114 - acc: 0.6786 - val_loss: 0.6519 - val_acc: 0.6334\n",
      "Epoch 40/50\n",
      "0s - loss: 0.6103 - acc: 0.6776 - val_loss: 0.6581 - val_acc: 0.6216\n",
      "Epoch 41/50\n",
      "0s - loss: 0.6102 - acc: 0.6727 - val_loss: 0.6531 - val_acc: 0.6334\n",
      "Epoch 42/50\n",
      "0s - loss: 0.6085 - acc: 0.6796 - val_loss: 0.6554 - val_acc: 0.6326\n",
      "Epoch 43/50\n",
      "0s - loss: 0.6080 - acc: 0.6823 - val_loss: 0.6538 - val_acc: 0.6334\n",
      "Epoch 44/50\n",
      "0s - loss: 0.6072 - acc: 0.6802 - val_loss: 0.6544 - val_acc: 0.6279\n",
      "Epoch 45/50\n",
      "0s - loss: 0.6069 - acc: 0.6794 - val_loss: 0.6527 - val_acc: 0.6365\n",
      "Epoch 46/50\n",
      "0s - loss: 0.6065 - acc: 0.6819 - val_loss: 0.6544 - val_acc: 0.6255\n",
      "Epoch 47/50\n",
      "0s - loss: 0.6068 - acc: 0.6806 - val_loss: 0.6560 - val_acc: 0.6389\n",
      "Epoch 48/50\n",
      "0s - loss: 0.6052 - acc: 0.6821 - val_loss: 0.6939 - val_acc: 0.6153\n",
      "Epoch 49/50\n",
      "0s - loss: 0.6066 - acc: 0.6806 - val_loss: 0.6513 - val_acc: 0.6373\n",
      "Epoch 50/50\n",
      "0s - loss: 0.6036 - acc: 0.6843 - val_loss: 0.6731 - val_acc: 0.6208\n"
     ]
    }
   ],
   "source": [
    "model_fit2 = model2.fit(X_train, \n",
    "          train_y, \n",
    "          batch_size=254,\n",
    "          epochs=50, \n",
    "          validation_split = .2,\n",
    "         verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  32/1589 [..............................] - ETA: 1s"
     ]
    }
   ],
   "source": [
    "y_hat2 = model2.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>M_F_P</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>967</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "M_F_P    0    1\n",
       "row_0          \n",
       "0      967  523\n",
       "1       37   62"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_hat2, df_test['M_F_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wrong = [im for im in zip(X_test, y_hat2, df_test['M_F_P']) if im[1] != im[2]]\n",
    "len(test_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2_acc = model_fit2.history['acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.add(Dense(1024, activation='relu', input_shape=(15,)))\n",
    "model3.add(Dense(524, activation='relu'))\n",
    "model3.add(Dense(1024, activation='relu'))\n",
    "model3.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 1024)              16384     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 524)               537100    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              537600    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 1,093,134\n",
      "Trainable params: 1,093,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.compile(optimizer=RMSprop(),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5084 samples, validate on 1271 samples\n",
      "Epoch 1/50\n",
      "1s - loss: 0.6672 - acc: 0.6212 - val_loss: 0.6709 - val_acc: 0.6090\n",
      "Epoch 2/50\n",
      "1s - loss: 0.6506 - acc: 0.6420 - val_loss: 0.6941 - val_acc: 0.6129\n",
      "Epoch 3/50\n",
      "1s - loss: 0.6394 - acc: 0.6456 - val_loss: 0.6894 - val_acc: 0.6200\n",
      "Epoch 4/50\n",
      "1s - loss: 0.6355 - acc: 0.6534 - val_loss: 0.7203 - val_acc: 0.5610\n",
      "Epoch 5/50\n",
      "1s - loss: 0.6251 - acc: 0.6648 - val_loss: 0.6726 - val_acc: 0.6192\n",
      "Epoch 6/50\n",
      "1s - loss: 0.6212 - acc: 0.6674 - val_loss: 0.6699 - val_acc: 0.6168\n",
      "Epoch 7/50\n",
      "1s - loss: 0.6227 - acc: 0.6566 - val_loss: 0.7128 - val_acc: 0.5114\n",
      "Epoch 8/50\n",
      "1s - loss: 0.6181 - acc: 0.6668 - val_loss: 0.7827 - val_acc: 0.6176\n",
      "Epoch 9/50\n",
      "1s - loss: 0.6121 - acc: 0.6819 - val_loss: 0.7732 - val_acc: 0.6176\n",
      "Epoch 10/50\n",
      "1s - loss: 0.6028 - acc: 0.6823 - val_loss: 0.7079 - val_acc: 0.6113\n",
      "Epoch 11/50\n",
      "1s - loss: 0.5963 - acc: 0.6898 - val_loss: 0.6940 - val_acc: 0.6161\n",
      "Epoch 12/50\n",
      "1s - loss: 0.5888 - acc: 0.6951 - val_loss: 0.6748 - val_acc: 0.6003\n",
      "Epoch 13/50\n",
      "1s - loss: 0.5834 - acc: 0.6959 - val_loss: 0.6915 - val_acc: 0.6192\n",
      "Epoch 14/50\n",
      "1s - loss: 0.5836 - acc: 0.7008 - val_loss: 0.6568 - val_acc: 0.6373\n",
      "Epoch 15/50\n",
      "1s - loss: 0.5745 - acc: 0.7065 - val_loss: 0.7396 - val_acc: 0.6341\n",
      "Epoch 16/50\n",
      "1s - loss: 0.5700 - acc: 0.7103 - val_loss: 0.6832 - val_acc: 0.6349\n",
      "Epoch 17/50\n",
      "1s - loss: 0.5643 - acc: 0.7172 - val_loss: 0.6877 - val_acc: 0.6042\n",
      "Epoch 18/50\n",
      "1s - loss: 0.5584 - acc: 0.7219 - val_loss: 0.7507 - val_acc: 0.6326\n",
      "Epoch 19/50\n",
      "1s - loss: 0.5560 - acc: 0.7209 - val_loss: 0.7405 - val_acc: 0.5594\n",
      "Epoch 20/50\n",
      "1s - loss: 0.5524 - acc: 0.7244 - val_loss: 0.8190 - val_acc: 0.6286\n",
      "Epoch 21/50\n",
      "1s - loss: 0.5510 - acc: 0.7244 - val_loss: 0.7220 - val_acc: 0.6404\n",
      "Epoch 22/50\n",
      "1s - loss: 0.5333 - acc: 0.7327 - val_loss: 0.6804 - val_acc: 0.6452\n",
      "Epoch 23/50\n",
      "1s - loss: 0.5376 - acc: 0.7305 - val_loss: 0.7205 - val_acc: 0.6404\n",
      "Epoch 24/50\n",
      "1s - loss: 0.5282 - acc: 0.7345 - val_loss: 0.7804 - val_acc: 0.6011\n",
      "Epoch 25/50\n",
      "1s - loss: 0.5270 - acc: 0.7354 - val_loss: 0.8627 - val_acc: 0.6302\n",
      "Epoch 26/50\n",
      "1s - loss: 0.5203 - acc: 0.7400 - val_loss: 0.7695 - val_acc: 0.5932\n",
      "Epoch 27/50\n",
      "1s - loss: 0.5150 - acc: 0.7425 - val_loss: 0.8673 - val_acc: 0.6341\n",
      "Epoch 28/50\n",
      "1s - loss: 0.5193 - acc: 0.7431 - val_loss: 0.7063 - val_acc: 0.6444\n",
      "Epoch 29/50\n",
      "1s - loss: 0.5083 - acc: 0.7480 - val_loss: 0.7688 - val_acc: 0.6216\n",
      "Epoch 30/50\n",
      "1s - loss: 0.5008 - acc: 0.7498 - val_loss: 0.7914 - val_acc: 0.6334\n",
      "Epoch 31/50\n",
      "1s - loss: 0.5014 - acc: 0.7569 - val_loss: 0.7182 - val_acc: 0.6397\n",
      "Epoch 32/50\n",
      "1s - loss: 0.4826 - acc: 0.7598 - val_loss: 0.7297 - val_acc: 0.6365\n",
      "Epoch 33/50\n",
      "1s - loss: 0.4851 - acc: 0.7653 - val_loss: 0.7919 - val_acc: 0.5980\n",
      "Epoch 34/50\n",
      "1s - loss: 0.4793 - acc: 0.7693 - val_loss: 0.7908 - val_acc: 0.6404\n",
      "Epoch 35/50\n",
      "1s - loss: 0.4676 - acc: 0.7764 - val_loss: 0.8426 - val_acc: 0.6475\n",
      "Epoch 36/50\n",
      "1s - loss: 0.4814 - acc: 0.7653 - val_loss: 0.8736 - val_acc: 0.6507\n",
      "Epoch 37/50\n",
      "1s - loss: 0.4678 - acc: 0.7701 - val_loss: 0.8270 - val_acc: 0.6223\n",
      "Epoch 38/50\n",
      "1s - loss: 0.4653 - acc: 0.7712 - val_loss: 0.8838 - val_acc: 0.6255\n",
      "Epoch 39/50\n",
      "1s - loss: 0.4725 - acc: 0.7734 - val_loss: 1.0091 - val_acc: 0.6538\n",
      "Epoch 40/50\n",
      "1s - loss: 0.4514 - acc: 0.7874 - val_loss: 0.8230 - val_acc: 0.6113\n",
      "Epoch 41/50\n",
      "1s - loss: 0.4463 - acc: 0.7823 - val_loss: 0.7835 - val_acc: 0.6530\n",
      "Epoch 42/50\n",
      "1s - loss: 0.4482 - acc: 0.7811 - val_loss: 0.7719 - val_acc: 0.6318\n",
      "Epoch 43/50\n",
      "1s - loss: 0.4349 - acc: 0.7882 - val_loss: 0.9972 - val_acc: 0.6326\n",
      "Epoch 44/50\n",
      "1s - loss: 0.4267 - acc: 0.7998 - val_loss: 1.0272 - val_acc: 0.6113\n",
      "Epoch 45/50\n",
      "1s - loss: 0.4291 - acc: 0.7925 - val_loss: 0.8235 - val_acc: 0.6389\n",
      "Epoch 46/50\n",
      "1s - loss: 0.4244 - acc: 0.7925 - val_loss: 0.8718 - val_acc: 0.6231\n",
      "Epoch 47/50\n",
      "1s - loss: 0.4208 - acc: 0.7984 - val_loss: 0.9463 - val_acc: 0.6491\n",
      "Epoch 48/50\n",
      "1s - loss: 0.4192 - acc: 0.8000 - val_loss: 1.0476 - val_acc: 0.6554\n",
      "Epoch 49/50\n",
      "1s - loss: 0.4117 - acc: 0.8072 - val_loss: 0.9805 - val_acc: 0.6302\n",
      "Epoch 50/50\n",
      "1s - loss: 0.4137 - acc: 0.8021 - val_loss: 0.8995 - val_acc: 0.6625\n"
     ]
    }
   ],
   "source": [
    "model_fit3 = model3.fit(X_train, \n",
    "          train_y, \n",
    "          batch_size=254,\n",
    "          epochs=50, \n",
    "          validation_split = .2,\n",
    "         verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1504/1589 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_hat3 = model3.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>M_F_P</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>728</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "M_F_P    0    1\n",
       "row_0          \n",
       "0      728  243\n",
       "1      276  342"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_hat3, df_test['M_F_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wrong = [im for im in zip(X_test, y_hat3, df_test['M_F_P']) if im[1] != im[2]]\n",
    "len(test_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3_acc = model_fit3.history['acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(300, activation='relu', input_shape=(15,)))\n",
    "model4.add(Dense(524, activation='relu'))\n",
    "model4.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 300)               4800      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 524)               157724    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 1050      \n",
      "=================================================================\n",
      "Total params: 163,574\n",
      "Trainable params: 163,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5084 samples, validate on 1271 samples\n",
      "Epoch 1/50\n",
      "0s - loss: 0.6567 - acc: 0.6275 - val_loss: 0.6798 - val_acc: 0.5814\n",
      "Epoch 2/50\n",
      "0s - loss: 0.6475 - acc: 0.6432 - val_loss: 0.6660 - val_acc: 0.6082\n",
      "Epoch 3/50\n",
      "0s - loss: 0.6377 - acc: 0.6520 - val_loss: 0.6705 - val_acc: 0.6019\n",
      "Epoch 4/50\n",
      "0s - loss: 0.6338 - acc: 0.6548 - val_loss: 0.7267 - val_acc: 0.6121\n",
      "Epoch 5/50\n",
      "0s - loss: 0.6319 - acc: 0.6603 - val_loss: 0.7629 - val_acc: 0.4618\n",
      "Epoch 6/50\n",
      "0s - loss: 0.6319 - acc: 0.6572 - val_loss: 0.6721 - val_acc: 0.6239\n",
      "Epoch 7/50\n",
      "0s - loss: 0.6217 - acc: 0.6676 - val_loss: 0.8076 - val_acc: 0.6082\n",
      "Epoch 8/50\n",
      "0s - loss: 0.6269 - acc: 0.6674 - val_loss: 0.7982 - val_acc: 0.6082\n",
      "Epoch 9/50\n",
      "0s - loss: 0.6209 - acc: 0.6770 - val_loss: 0.6538 - val_acc: 0.6341\n",
      "Epoch 10/50\n",
      "0s - loss: 0.6114 - acc: 0.6741 - val_loss: 0.6816 - val_acc: 0.6082\n",
      "Epoch 11/50\n",
      "0s - loss: 0.6102 - acc: 0.6792 - val_loss: 0.6927 - val_acc: 0.5602\n",
      "Epoch 12/50\n",
      "0s - loss: 0.6059 - acc: 0.6790 - val_loss: 0.6910 - val_acc: 0.6223\n",
      "Epoch 13/50\n",
      "0s - loss: 0.6036 - acc: 0.6845 - val_loss: 0.6797 - val_acc: 0.6373\n",
      "Epoch 14/50\n",
      "0s - loss: 0.6028 - acc: 0.6819 - val_loss: 0.6951 - val_acc: 0.6192\n",
      "Epoch 15/50\n",
      "0s - loss: 0.5999 - acc: 0.6851 - val_loss: 0.6718 - val_acc: 0.6412\n",
      "Epoch 16/50\n",
      "0s - loss: 0.5963 - acc: 0.6880 - val_loss: 0.6851 - val_acc: 0.6168\n",
      "Epoch 17/50\n",
      "0s - loss: 0.5953 - acc: 0.6906 - val_loss: 0.6784 - val_acc: 0.5885\n",
      "Epoch 18/50\n",
      "0s - loss: 0.5922 - acc: 0.6914 - val_loss: 0.7148 - val_acc: 0.5767\n",
      "Epoch 19/50\n",
      "0s - loss: 0.5950 - acc: 0.6904 - val_loss: 0.8259 - val_acc: 0.6066\n",
      "Epoch 20/50\n",
      "0s - loss: 0.5931 - acc: 0.6918 - val_loss: 0.6686 - val_acc: 0.6090\n",
      "Epoch 21/50\n",
      "0s - loss: 0.5887 - acc: 0.6918 - val_loss: 0.6759 - val_acc: 0.6341\n",
      "Epoch 22/50\n",
      "0s - loss: 0.5856 - acc: 0.6937 - val_loss: 0.6779 - val_acc: 0.6357\n",
      "Epoch 23/50\n",
      "0s - loss: 0.5848 - acc: 0.6991 - val_loss: 0.6685 - val_acc: 0.6208\n",
      "Epoch 24/50\n",
      "0s - loss: 0.5841 - acc: 0.7014 - val_loss: 0.7443 - val_acc: 0.5586\n",
      "Epoch 25/50\n",
      "0s - loss: 0.5811 - acc: 0.6994 - val_loss: 0.6572 - val_acc: 0.6381\n",
      "Epoch 26/50\n",
      "0s - loss: 0.5752 - acc: 0.7054 - val_loss: 0.6579 - val_acc: 0.6420\n",
      "Epoch 27/50\n",
      "0s - loss: 0.5759 - acc: 0.7063 - val_loss: 0.7040 - val_acc: 0.6279\n",
      "Epoch 28/50\n",
      "0s - loss: 0.5748 - acc: 0.7018 - val_loss: 0.6660 - val_acc: 0.6428\n",
      "Epoch 29/50\n",
      "0s - loss: 0.5702 - acc: 0.7061 - val_loss: 0.7753 - val_acc: 0.6161\n",
      "Epoch 30/50\n",
      "0s - loss: 0.5697 - acc: 0.7057 - val_loss: 0.6877 - val_acc: 0.6184\n",
      "Epoch 31/50\n",
      "0s - loss: 0.5657 - acc: 0.7089 - val_loss: 0.7469 - val_acc: 0.6310\n",
      "Epoch 32/50\n",
      "0s - loss: 0.5666 - acc: 0.7116 - val_loss: 0.7623 - val_acc: 0.5397\n",
      "Epoch 33/50\n",
      "0s - loss: 0.5637 - acc: 0.7065 - val_loss: 0.6636 - val_acc: 0.6239\n",
      "Epoch 34/50\n",
      "0s - loss: 0.5578 - acc: 0.7207 - val_loss: 0.7524 - val_acc: 0.5397\n",
      "Epoch 35/50\n",
      "0s - loss: 0.5636 - acc: 0.7089 - val_loss: 0.7005 - val_acc: 0.6050\n",
      "Epoch 36/50\n",
      "0s - loss: 0.5589 - acc: 0.7154 - val_loss: 0.8032 - val_acc: 0.6129\n",
      "Epoch 37/50\n",
      "0s - loss: 0.5622 - acc: 0.7095 - val_loss: 0.8112 - val_acc: 0.6184\n",
      "Epoch 38/50\n",
      "0s - loss: 0.5609 - acc: 0.7164 - val_loss: 0.6883 - val_acc: 0.6121\n",
      "Epoch 39/50\n",
      "0s - loss: 0.5513 - acc: 0.7229 - val_loss: 0.7308 - val_acc: 0.5901\n",
      "Epoch 40/50\n",
      "0s - loss: 0.5571 - acc: 0.7134 - val_loss: 0.6830 - val_acc: 0.6239\n",
      "Epoch 41/50\n",
      "0s - loss: 0.5452 - acc: 0.7252 - val_loss: 0.7620 - val_acc: 0.6247\n",
      "Epoch 42/50\n",
      "0s - loss: 0.5532 - acc: 0.7234 - val_loss: 0.8035 - val_acc: 0.6137\n",
      "Epoch 43/50\n",
      "0s - loss: 0.5523 - acc: 0.7211 - val_loss: 0.6978 - val_acc: 0.6436\n",
      "Epoch 44/50\n",
      "0s - loss: 0.5412 - acc: 0.7295 - val_loss: 0.6657 - val_acc: 0.6444\n",
      "Epoch 45/50\n",
      "0s - loss: 0.5488 - acc: 0.7207 - val_loss: 0.6736 - val_acc: 0.6184\n",
      "Epoch 46/50\n",
      "0s - loss: 0.5410 - acc: 0.7297 - val_loss: 0.8135 - val_acc: 0.6168\n",
      "Epoch 47/50\n",
      "0s - loss: 0.5432 - acc: 0.7254 - val_loss: 0.7013 - val_acc: 0.6105\n",
      "Epoch 48/50\n",
      "0s - loss: 0.5386 - acc: 0.7256 - val_loss: 0.6776 - val_acc: 0.6192\n",
      "Epoch 49/50\n",
      "0s - loss: 0.5398 - acc: 0.7331 - val_loss: 0.6874 - val_acc: 0.6404\n",
      "Epoch 50/50\n",
      "0s - loss: 0.5347 - acc: 0.7305 - val_loss: 0.7008 - val_acc: 0.6279\n"
     ]
    }
   ],
   "source": [
    "model4.compile(optimizer=RMSprop(),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model_fit4 = model4.fit(X_train, \n",
    "          train_y, \n",
    "          batch_size=254,\n",
    "          epochs=50, \n",
    "          validation_split = .2,\n",
    "         verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1504/1589 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_hat4 = model4.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>M_F_P</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "M_F_P    0    1\n",
       "row_0          \n",
       "0      768  304\n",
       "1      236  281"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_hat4, df_test['M_F_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wrong = [im for im in zip(X_test, y_hat4, df_test['M_F_P']) if im[1] != im[2]]\n",
    "len(test_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4_acc = model_fit4.history['acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(400, activation='relu', input_shape=(15,)))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Dense(600, activation='relu', input_shape=(15,)))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 400)               6400      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 600)               240600    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 1202      \n",
      "=================================================================\n",
      "Total params: 248,202\n",
      "Trainable params: 248,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3813 samples, validate on 2542 samples\n",
      "Epoch 1/50\n",
      "0s - loss: 0.6642 - acc: 0.6263 - val_loss: 0.6596 - val_acc: 0.6298\n",
      "Epoch 2/50\n",
      "0s - loss: 0.6521 - acc: 0.6341 - val_loss: 0.6732 - val_acc: 0.5858\n",
      "Epoch 3/50\n",
      "0s - loss: 0.6466 - acc: 0.6465 - val_loss: 0.6589 - val_acc: 0.6306\n",
      "Epoch 4/50\n",
      "0s - loss: 0.6418 - acc: 0.6462 - val_loss: 0.6546 - val_acc: 0.6381\n",
      "Epoch 5/50\n",
      "0s - loss: 0.6378 - acc: 0.6501 - val_loss: 0.7474 - val_acc: 0.6251\n",
      "Epoch 6/50\n",
      "0s - loss: 0.6408 - acc: 0.6538 - val_loss: 0.6613 - val_acc: 0.6373\n",
      "Epoch 7/50\n",
      "0s - loss: 0.6297 - acc: 0.6659 - val_loss: 0.6521 - val_acc: 0.6432\n",
      "Epoch 8/50\n",
      "0s - loss: 0.6285 - acc: 0.6609 - val_loss: 0.6471 - val_acc: 0.6463\n",
      "Epoch 9/50\n",
      "0s - loss: 0.6306 - acc: 0.6690 - val_loss: 0.6463 - val_acc: 0.6479\n",
      "Epoch 10/50\n",
      "0s - loss: 0.6250 - acc: 0.6743 - val_loss: 0.7098 - val_acc: 0.6275\n",
      "Epoch 11/50\n",
      "0s - loss: 0.6288 - acc: 0.6606 - val_loss: 0.6443 - val_acc: 0.6503\n",
      "Epoch 12/50\n",
      "0s - loss: 0.6198 - acc: 0.6714 - val_loss: 0.6663 - val_acc: 0.5995\n",
      "Epoch 13/50\n",
      "0s - loss: 0.6232 - acc: 0.6656 - val_loss: 0.6471 - val_acc: 0.6522\n",
      "Epoch 14/50\n",
      "0s - loss: 0.6152 - acc: 0.6758 - val_loss: 0.6666 - val_acc: 0.6243\n",
      "Epoch 15/50\n",
      "0s - loss: 0.6154 - acc: 0.6785 - val_loss: 0.6637 - val_acc: 0.6444\n",
      "Epoch 16/50\n",
      "0s - loss: 0.6160 - acc: 0.6740 - val_loss: 0.7014 - val_acc: 0.5767\n",
      "Epoch 17/50\n",
      "0s - loss: 0.6126 - acc: 0.6785 - val_loss: 0.6747 - val_acc: 0.6424\n",
      "Epoch 18/50\n",
      "0s - loss: 0.6120 - acc: 0.6774 - val_loss: 0.6360 - val_acc: 0.6483\n",
      "Epoch 19/50\n",
      "0s - loss: 0.6080 - acc: 0.6798 - val_loss: 0.6372 - val_acc: 0.6459\n",
      "Epoch 20/50\n",
      "0s - loss: 0.6069 - acc: 0.6806 - val_loss: 0.6695 - val_acc: 0.6239\n",
      "Epoch 21/50\n",
      "0s - loss: 0.6085 - acc: 0.6772 - val_loss: 0.6442 - val_acc: 0.6526\n",
      "Epoch 22/50\n",
      "0s - loss: 0.6022 - acc: 0.6863 - val_loss: 0.6558 - val_acc: 0.6436\n",
      "Epoch 23/50\n",
      "0s - loss: 0.6045 - acc: 0.6871 - val_loss: 0.6858 - val_acc: 0.5964\n",
      "Epoch 24/50\n",
      "0s - loss: 0.6057 - acc: 0.6816 - val_loss: 0.6481 - val_acc: 0.6495\n",
      "Epoch 25/50\n",
      "0s - loss: 0.5934 - acc: 0.6892 - val_loss: 0.6524 - val_acc: 0.6483\n",
      "Epoch 26/50\n",
      "0s - loss: 0.5977 - acc: 0.6866 - val_loss: 0.6576 - val_acc: 0.6243\n",
      "Epoch 27/50\n",
      "0s - loss: 0.5966 - acc: 0.6882 - val_loss: 0.6437 - val_acc: 0.6373\n",
      "Epoch 28/50\n",
      "0s - loss: 0.5944 - acc: 0.6958 - val_loss: 0.6620 - val_acc: 0.6452\n",
      "Epoch 29/50\n",
      "0s - loss: 0.5941 - acc: 0.6903 - val_loss: 0.6451 - val_acc: 0.6562\n",
      "Epoch 30/50\n",
      "0s - loss: 0.5969 - acc: 0.6866 - val_loss: 0.6494 - val_acc: 0.6397\n",
      "Epoch 31/50\n",
      "0s - loss: 0.5889 - acc: 0.6939 - val_loss: 0.6718 - val_acc: 0.6515\n",
      "Epoch 32/50\n",
      "0s - loss: 0.5885 - acc: 0.6979 - val_loss: 0.6486 - val_acc: 0.6629\n",
      "Epoch 33/50\n",
      "0s - loss: 0.5845 - acc: 0.6966 - val_loss: 0.6503 - val_acc: 0.6459\n",
      "Epoch 34/50\n",
      "0s - loss: 0.5842 - acc: 0.7008 - val_loss: 0.6455 - val_acc: 0.6585\n",
      "Epoch 35/50\n",
      "0s - loss: 0.5842 - acc: 0.6994 - val_loss: 0.7467 - val_acc: 0.6334\n",
      "Epoch 36/50\n",
      "0s - loss: 0.5856 - acc: 0.6916 - val_loss: 0.6724 - val_acc: 0.6066\n",
      "Epoch 37/50\n",
      "0s - loss: 0.5798 - acc: 0.7068 - val_loss: 0.6399 - val_acc: 0.6593\n",
      "Epoch 38/50\n",
      "0s - loss: 0.5837 - acc: 0.6974 - val_loss: 0.6483 - val_acc: 0.6306\n",
      "Epoch 39/50\n",
      "0s - loss: 0.5745 - acc: 0.7036 - val_loss: 0.6397 - val_acc: 0.6456\n",
      "Epoch 40/50\n",
      "0s - loss: 0.5755 - acc: 0.7008 - val_loss: 0.6390 - val_acc: 0.6522\n",
      "Epoch 41/50\n",
      "0s - loss: 0.5753 - acc: 0.7060 - val_loss: 0.6488 - val_acc: 0.6424\n",
      "Epoch 42/50\n",
      "0s - loss: 0.5739 - acc: 0.7063 - val_loss: 0.6675 - val_acc: 0.6499\n",
      "Epoch 43/50\n",
      "0s - loss: 0.5729 - acc: 0.7065 - val_loss: 0.6388 - val_acc: 0.6526\n",
      "Epoch 44/50\n",
      "0s - loss: 0.5673 - acc: 0.7115 - val_loss: 0.6303 - val_acc: 0.6574\n",
      "Epoch 45/50\n",
      "0s - loss: 0.5688 - acc: 0.7023 - val_loss: 0.6382 - val_acc: 0.6589\n",
      "Epoch 46/50\n",
      "0s - loss: 0.5674 - acc: 0.7162 - val_loss: 0.7362 - val_acc: 0.5712\n",
      "Epoch 47/50\n",
      "0s - loss: 0.5707 - acc: 0.7063 - val_loss: 0.6400 - val_acc: 0.6566\n",
      "Epoch 48/50\n",
      "0s - loss: 0.5654 - acc: 0.7089 - val_loss: 0.8500 - val_acc: 0.5122\n",
      "Epoch 49/50\n",
      "0s - loss: 0.5772 - acc: 0.7086 - val_loss: 0.6470 - val_acc: 0.6550\n",
      "Epoch 50/50\n",
      "0s - loss: 0.5550 - acc: 0.7270 - val_loss: 0.6866 - val_acc: 0.6499\n"
     ]
    }
   ],
   "source": [
    "model5.compile(optimizer=RMSprop(),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model_fit5 = model5.fit(X_train, \n",
    "          train_y, \n",
    "          batch_size=254,\n",
    "          epochs=50, \n",
    "          validation_split = .40,\n",
    "         verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 928/1589 [================>.............] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_hat5 = model5.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wrong = [im for im in zip(X_test, y_hat5, df_test['M_F_P']) if im[1] != im[2]]\n",
    "len(test_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>M_F_P</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>979</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "M_F_P    0    1\n",
       "row_0          \n",
       "0      979  519\n",
       "1       25   66"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_hat5, df_test['M_F_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model5_acc = model_fit5.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc7832d7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.fig\n",
    "plt.plot(range(1,51), model1_acc, color = 'green', )\n",
    "plt.plot(range(1,51), model2_acc, color = 'red', )\n",
    "plt.plot(range(1,51), model3_acc, color = 'black', )\n",
    "plt.plot(range(1,51), model4_acc, color = 'yellow', )\n",
    "plt.plot(range(1,51), model5_acc, color = 'blue', )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
